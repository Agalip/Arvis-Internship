{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa1d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARVIS TECH Internship Programme\n",
    "#September 2022\n",
    "\n",
    "#Pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a95415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.signal import filtfilt, butter, lfilter, medfilt\n",
    "from matplotlib import pyplot as plt \n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2772a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon(image, coordinates, facial_landmarks):\n",
    "    #returns the region in the frame as a polygon for the selected landmark points.\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    area = []\n",
    "    for i in coordinates:\n",
    "        pt1 = facial_landmarks.landmark[i]\n",
    "        x = int(pt1.x * width)\n",
    "        y = int(pt1.y * height)\n",
    "        area.append([x,y])\n",
    "        #cv2.circle(image, (x, y), 2, (100, 100, 0), -1)\n",
    "        #cv2.putText(image, str(i), (x, y), 0, 0.5, (0, 0, 0))\n",
    "        \n",
    "    area = np.array(area)\n",
    "    area = area.reshape((-1, 1, 2))\n",
    "    #cv2.polylines(image,[area],True,(0,255,255))\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d13153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(image, yanak_sag , yanak_sol, alin):\n",
    "    #this function extracts ROI areas and put them on a black background from the base image\n",
    "\n",
    "    mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "    cv2.drawContours(mask, [yanak_sag], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    cv2.drawContours(mask, [yanak_sol], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    cv2.drawContours(mask, [alin], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    output = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e2077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def green(image, area):\n",
    "    #function to find green channel averages of given image and ROI\n",
    "\n",
    "    mask_G = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "    cv2.drawContours(mask_G, [area], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    mean = cv2.mean(image[:,:,1], mask=mask_G)\n",
    "    #print(f\"{txt}= {mean}\")\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2937a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_signal(green_mean, green_arr, n_frames):\n",
    "    #updates green channel array signal\n",
    "    \n",
    "    #if size of array is less than given limit, it appends the green channel mean to the signal array\n",
    "    if len(green_arr) < n_frames:\n",
    "        green_arr.append(green_mean)\n",
    "        \n",
    "    #else it keeps the size of the array constant by deleting an element from the beginning and appending an element to the end\n",
    "    else:\n",
    "        del green_arr[0]\n",
    "        green_arr.append(green_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3777a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nabiz_bul(mean_list, fps, hz_bottom, hz_top):\n",
    "    \n",
    "    sampling_rate = fps\n",
    "    raw_signal = np.squeeze(mean_list)\n",
    "    \n",
    "    \n",
    "    #We applied the Z-score normalization method to the raw signal.\n",
    "    #This process makes the mean of the raw signal 0 and its standard deviation 1.\n",
    "    #General formula of Z-score normalization (signal - avg(signal))/std(signal).\n",
    "    #The reason why we do normalization is to put all the values in the same range before putting the signal into the median filter.\n",
    "    #so the median filter works better when trying to find the median value.\n",
    "    normalized_signal = raw_signal - np.mean(raw_signal)#We used the formula which I mentioned above.\n",
    "    normalized_signal = normalized_signal / np.std(normalized_signal)#We used the formula which I mentioned above.\n",
    "    \n",
    "    \n",
    "    \n",
    "    #We apply a median filter to the normalized signal.\n",
    "    #The reason why we apply a median filter to the signal is to remove noise by preventing spikes in the signal.\n",
    "    #smoothes out spikes in the signal\n",
    "    med_signal = medfilt(normalized_signal, 5)#applying a median filter to the normalized signal (window size is 5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #A band-pass Butterworth filter is applied to the signal.\n",
    "    #In this part, while we receive signals within the signal range we want, we eliminate the signals outside of the range.\n",
    "    #for example, if you just want to measure 60 to 180 pulse range: 60/60=1Hz 180/60=3Hz(lower and upper limit in frequency)\n",
    "    nyq = 0.5 * sampling_rate#We applied the nyquist frequency formula.(fn = 1/2Î”t )\n",
    "    low = hz_bottom / nyq#lower frequency limit for our band-pass filter\n",
    "    high = hz_top / nyq#upper frequency limit for our band-pass filter\n",
    "    b, a = butter(3, [low, high], btype = 'band')#Prepares a 3rd degree band-pass butterworth filter and returns the filter coefficients.\n",
    "    filtered_signal = lfilter(b, a, med_signal)#filter the signal\n",
    "    \n",
    "    \n",
    "    #we apply a hamming window to the signal\n",
    "    #Window functions are multiplier functions of signal parts.\n",
    "    #With the help of these functions, it is ensured that the middle parts of the signal parts are highlighted.\n",
    "    #The parts near the beginning and end of the windows are extinguished. In this way, spectral leakage is attenuated.\n",
    "    window = np.hamming(len(filtered_signal))#prepares the hamming window multiplier function\n",
    "    windowed_signal = filtered_signal * window#The signal is multiplied by the multiplier function.\n",
    "    \n",
    "    \n",
    "    \n",
    "    #this is where FFT and Power spectrum are applied to the signal.\n",
    "    #FFT Converts the signal from time domain to frequency domain.\n",
    "    #The frequency domain is in the set of complex numbers.\n",
    "    #We convert this set to the set of real numbers by multiplying it by its conjugate.\n",
    "    #The frequency spectrum transferred to real numbers is called power spectrum.\n",
    "    def nextpow(x):\n",
    "        return 2 ** math.ceil(math.log2(x))\n",
    "\n",
    "    NFFT = nextpow(len(windowed_signal) * sampling_rate)#Length of the transformed axis of the output (we applied 0 padding)\n",
    "    freqDomain = np.fft.fft(windowed_signal, NFFT)#Calculates the one-dimensional discrete Fourier Transform (we move to the frequency range)\n",
    "    conj = np.conjugate(freqDomain)#the conjugate of the frequency range is taken\n",
    "\n",
    "    powerSpectrum = np.multiply(freqDomain, conj) / NFFT#The frequency range is multiplied by its conjugate to get the real number range.\n",
    "    powerSpectrum = np.real(powerSpectrum)#even though complex values are eliminated the complex parts are still shown as 0j.The 0j portions are removed.\n",
    "\n",
    "    freqInterestL = hz_bottom#predetermined lower frequency limit\n",
    "    freqInterestH = hz_top#predetermined upper frequency limit\n",
    "\n",
    "    freqs = np.linspace(0, sampling_rate, NFFT)#Divide the length from 0 to NFFT into steps of sampling_rate size.\n",
    "    fRange = list()\n",
    "    #Browse the sampled frequencies and add indexes to the list if the frequencies fall within the range of interest.\n",
    "    for i in range(len(freqs)):\n",
    "        if freqs[i] < freqInterestH and freqs[i] > freqInterestL:\n",
    "            fRange.append(i + 1)\n",
    "    #Return the selected indexes in Hz.\n",
    "    HRange = list()\n",
    "    for i in range(len(fRange)):\n",
    "        idx = 60 * freqs[fRange[i]]\n",
    "        HRange.append(idx)\n",
    "    max_x = HRange[powerSpectrum[fRange].argmax()]#Get the highest value in HRange\n",
    "    return max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20118b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pulse(path = 0, plot_signal = False):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    #finds the fps of the video\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "    else :\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "    # Face Mesh\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "    \n",
    "    #array to store green channel means of each frame   \n",
    "    green_arr = []\n",
    "    \n",
    "    #array to store pulse values   \n",
    "    nabiz = []\n",
    "\n",
    "\n",
    "    # Create figure and subplot\n",
    "    if plot_signal:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        \n",
    "    #frame counter\n",
    "    ctr = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        if ret is not True:\n",
    "            break\n",
    "\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Facial landmarks\n",
    "        result = face_mesh.process(rgb_image)\n",
    "        \n",
    "        #mediapipe crashes in case it cannot find a face to detect therefore try/except blocks used here\n",
    "        try:\n",
    "\n",
    "            for facial_landmarks in result.multi_face_landmarks:\n",
    "                \n",
    "                #left cheek landmark points \n",
    "                yanak_sol_arr = [143, 123, 147, 213, 138, 135, 210, 202, 57, 92, 36, 101, 118, 31, 143]\n",
    "                yanak_sol = polygon(image, yanak_sol_arr, facial_landmarks)\n",
    "\n",
    "            for facial_landmarks in result.multi_face_landmarks:\n",
    "                \n",
    "                #right cheek landmark points \n",
    "                yanak_sag_arr = [372, 352, 376, 433, 367, 364, 430, 422, 287, 322, 266, 330, 347, 261, 372]\n",
    "                yanak_sag = polygon(image, yanak_sag_arr, facial_landmarks)\n",
    "\n",
    "            for facial_landmarks in result.multi_face_landmarks:\n",
    "\n",
    "                #forehead landmark points \n",
    "                alin_arr = [54, 103, 67, 109, 10, 338, 297, 332, 284, 298, 296, 9, 66, 68,]\n",
    "                alin = polygon(image, alin_arr, facial_landmarks)\n",
    "\n",
    "            #extracts ROI areas from the base image\n",
    "            image = extract_roi(image, yanak_sag , yanak_sol, alin)\n",
    "            \n",
    "            #the green channel average of each ROI areas\n",
    "            mean_yanak_sag = green(image, yanak_sag)[0]\n",
    "            mean_yanak_sol = green(image, yanak_sol)[0]\n",
    "            mean_alin = green(image, alin)[0]\n",
    "            \n",
    "            #mean green channel value of all ROI areas combined\n",
    "            mean_raw = (mean_yanak_sag + mean_yanak_sol + mean_alin)/3\n",
    "            \n",
    "            #updates green channel array\n",
    "            #the limit of the array is 10 seconds.\n",
    "            update_signal(mean_raw, green_arr, n_frames=fps*10)\n",
    "            \n",
    "            #if size of green_array channel is greater than 3 seconds of frame size\n",
    "            #Without the if block, it would try to find a pulse value for an array that was not large enough\n",
    "            #that would cause an error.\n",
    "            if len(green_arr) >= fps*3:\n",
    "                \n",
    "                #finds pulse from the green channel signal\n",
    "                nabiz.append(nabiz_bul(green_arr, fps=fps, hz_bottom=1.0, hz_top=2.75))\n",
    "                \n",
    "                #putting the last element of the pulse on the frame\n",
    "                #If a smoother transition between pulse values is desired, \n",
    "                #the average of the last 3 seconds pulse values can be putted on the frane.\n",
    "                cv2.putText(image,\"PULSE: \" + str(round(nabiz[-1])), (150, 30), font, 1, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "            # putting the FPS count on the frame\n",
    "            cv2.putText(image, \"FPS: \" + str(int(fps)), (7, 30), font, 1, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "            \n",
    "            #plotting the green array signal\n",
    "            if plot_signal:\n",
    "                if ctr % (fps/2) == 0:\n",
    "                    ax.cla()\n",
    "                    ax.plot(green_arr)\n",
    "                    display(fig)    \n",
    "                    clear_output(wait = True)\n",
    "\n",
    "        #if mediapipe cannot detects face it prints \"No Face Detected\" to the screen\n",
    "        except:\n",
    "            text = \"No Face Detected\"\n",
    "            coordinates = (128,128)\n",
    "            fontScale = 1\n",
    "            color = (255,0,255)\n",
    "            thickness = 2\n",
    "            blank = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "            image = cv2.putText(blank, text, coordinates, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"roi areas\", image)\n",
    "        \n",
    "        ctr += 1\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break   \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2673a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 0\n",
    "find_pulse(path=path, plot_signal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39904fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb087800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
